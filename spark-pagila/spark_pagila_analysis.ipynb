{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ad38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# JDBC driver path\n",
    "jdbc_driver_path = r\"E:\\innowiseHW\\sparkhw\\spark-pagila\\postgresql-42.6.0.jar\"\n",
    "\n",
    "# Create Spark session once\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Pagila\") \\\n",
    "    .config(\"spark.jars\", jdbc_driver_path) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# JDBC connection options (reuse this dictionary)\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5433/pagila\"\n",
    "jdbc_options = {\n",
    "    \"url\": jdbc_url,\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123456\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# Function to read a table\n",
    "def read_table(table_name):\n",
    "    return spark.read.format(\"jdbc\") \\\n",
    "        .options(**jdbc_options, dbtable=table_name) \\\n",
    "        .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48f3438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+--------------------+--------------------+\n",
      "|film_id|           title|         description|release_year|language_id|original_language_id|rental_duration|rental_rate|length|replacement_cost|rating|         last_update|    special_features|            fulltext|\n",
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+--------------------+--------------------+\n",
      "|      1|ACADEMY DINOSAUR|A Epic Drama of a...|        2012|          1|                null|              6|       0.99|    86|           20.99|    PG|2022-09-10 21:46:...|[Deleted Scenes, ...|'academi':1 'batt...|\n",
      "|      2|  ACE GOLDFINGER|A Astounding Epis...|        2023|          1|                null|              3|       4.99|    48|           12.99|     G|2022-09-10 21:46:...|[Trailers, Delete...|'ace':1 'administ...|\n",
      "|      3|ADAPTATION HOLES|A Astounding Refl...|        2017|          2|                null|              7|       2.99|    50|           18.99| NC-17|2022-09-10 21:46:...|[Trailers, Delete...|'adapt':1 'astoun...|\n",
      "|      4|AFFAIR PREJUDICE|A Fanciful Docume...|        2023|          6|                null|              5|       2.99|   117|           26.99|     G|2022-09-10 21:46:...|[Commentaries, Be...|'affair':1 'chase...|\n",
      "|      5|     AFRICAN EGG|A Fast-Paced Docu...|        2019|          4|                null|              6|       2.99|   130|           22.99|     G|2022-09-10 21:46:...|    [Deleted Scenes]|'african':1 'chef...|\n",
      "|      6|    AGENT TRUMAN|A Intrepid Panora...|        2010|          1|                null|              3|       2.99|   169|           17.99|    PG|2022-09-10 21:46:...|    [Deleted Scenes]|'agent':1 'ancien...|\n",
      "|      7| AIRPLANE SIERRA|A Touching Saga o...|        2019|          1|                null|              6|       4.99|    62|           28.99| PG-13|2022-09-10 21:46:...|[Trailers, Delete...|'airplan':1 'boat...|\n",
      "|      8| AIRPORT POLLOCK|A Epic Tale of a ...|        2010|          1|                null|              6|       4.99|    54|           15.99|     R|2022-09-10 21:46:...|          [Trailers]|'airport':1 'anci...|\n",
      "|      9|   ALABAMA DEVIL|A Thoughtful Pano...|        2011|          1|                null|              3|       2.99|   114|           21.99| PG-13|2022-09-10 21:46:...|[Trailers, Delete...|'administr':9 'al...|\n",
      "|     10|ALADDIN CALENDAR|A Action-Packed T...|        2014|          1|                null|              6|       4.99|    63|           24.99| NC-17|2022-09-10 21:46:...|[Trailers, Delete...|'action':5 'actio...|\n",
      "+-------+----------------+--------------------+------------+-----------+--------------------+---------------+-----------+------+----------------+------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "film_df = read_table('film')\n",
    "film_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abaf630",
   "metadata": {},
   "source": [
    "(a) Number of movies in each category, sorted descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "462f2458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|       name|num_of_movies|\n",
      "+-----------+-------------+\n",
      "|      Drama|          152|\n",
      "|      Music|          152|\n",
      "|     Travel|          151|\n",
      "|    Foreign|          150|\n",
      "|      Games|          150|\n",
      "|   Children|          150|\n",
      "|     Action|          149|\n",
      "|     Sci-Fi|          149|\n",
      "|  Animation|          148|\n",
      "|     Family|          147|\n",
      "|   Classics|          147|\n",
      "|        New|          147|\n",
      "|     Sports|          145|\n",
      "|Documentary|          145|\n",
      "|     Comedy|          143|\n",
      "|     Horror|          142|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "film_category_df = read_table(\"film_category\")\n",
    "category_df = read_table(\"category\")\n",
    "\n",
    "movies_per_category = film_category_df \\\n",
    "    .join(category_df, 'category_id') \\\n",
    "    .groupby('name') \\\n",
    "    .agg(count('film_id').alias('num_of_movies')) \\\n",
    "    .orderBy(col('num_of_movies').desc())\n",
    "    \n",
    "movies_per_category.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3c946",
   "metadata": {},
   "source": [
    "(b) Top 10 actors whose movies were rented the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7df606a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----+\n",
      "|first_name|  last_name|count|\n",
      "+----------+-----------+-----+\n",
      "|     SUSAN|      DAVIS|  825|\n",
      "|      GINA|  DEGENERES|  753|\n",
      "|   MATTHEW|     CARREY|  678|\n",
      "|      MARY|     KEITEL|  674|\n",
      "|    ANGELA|WITHERSPOON|  654|\n",
      "|    WALTER|       TORN|  640|\n",
      "|     HENRY|      BERRY|  612|\n",
      "|     JAYNE|      NOLTE|  611|\n",
      "|       VAL|     BOLGER|  605|\n",
      "|    SANDRA|     KILMER|  604|\n",
      "+----------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "rental_df = read_table(\"rental\")\n",
    "inventory_df = read_table(\"inventory\")\n",
    "film_actor_df = read_table(\"film_actor\")\n",
    "actor_df = read_table(\"actor\")\n",
    "\n",
    "actor_rentals = rental_df \\\n",
    "    .join(inventory_df, \"inventory_id\") \\\n",
    "    .join(film_actor_df, \"film_id\") \\\n",
    "    .join(actor_df, \"actor_id\") \\\n",
    "    .groupBy(\"first_name\", \"last_name\") \\\n",
    "    .count() \\\n",
    "    .orderBy(desc(\"count\")) \\\n",
    "    .limit(10)\n",
    "\n",
    "actor_rentals.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9af3b",
   "metadata": {},
   "source": [
    "(c) Category of movies on which the most money was spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a5fc1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|       name|sum(amount)|\n",
      "+-----------+-----------+\n",
      "|    Foreign|   10507.67|\n",
      "|   Children|   10437.05|\n",
      "|  Animation|   10369.55|\n",
      "|Documentary|   10307.29|\n",
      "|     Action|   10289.60|\n",
      "|      Music|   10188.81|\n",
      "|     Sci-Fi|   10054.10|\n",
      "|        New|    9915.24|\n",
      "|     Sports|    9902.86|\n",
      "|      Games|    9848.23|\n",
      "|     Horror|    9807.69|\n",
      "|     Travel|    9793.98|\n",
      "|   Classics|    9708.77|\n",
      "|     Family|    9703.84|\n",
      "|      Drama|    9522.54|\n",
      "|     Comedy|    9181.93|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "payment_df = read_table(\"payment\")\n",
    "\n",
    "category_revenue = payment_df \\\n",
    "    .join(rental_df, 'rental_id') \\\n",
    "    .join(inventory_df, 'inventory_id') \\\n",
    "    .join(film_category_df, 'film_id') \\\n",
    "    .join(category_df, 'category_id') \\\n",
    "    .groupBy('name') \\\n",
    "    .sum('amount') \\\n",
    "    .orderBy(desc(\"sum(amount)\"))\n",
    "    \n",
    "category_revenue.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0404ec3",
   "metadata": {},
   "source": [
    "(d) Names of movies that are not in the inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95229138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               title|\n",
      "+--------------------+\n",
      "|      CHOCOLATE DUCK|\n",
      "|       BUTCH PANTHER|\n",
      "|        VOLUME HOUSE|\n",
      "|      ORDER BETRAYED|\n",
      "|        TADPOLE PARK|\n",
      "|    KILL BROTHERHOOD|\n",
      "|FRANKENSTEIN STRA...|\n",
      "|    CROSSING DIVORCE|\n",
      "|    SUICIDES SILENCE|\n",
      "|       CATCH AMISTAD|\n",
      "|     PERDITION FARGO|\n",
      "|       FLOATS GARDEN|\n",
      "|           GUMP DATE|\n",
      "|        WALLS ARTIST|\n",
      "|  GLADIATOR WESTWARD|\n",
      "|         HOCUS FRIDA|\n",
      "|ARSENIC INDEPENDENCE|\n",
      "|         MUPPET MILE|\n",
      "|   FIREHOUSE VIETNAM|\n",
      "|       ROOF CHAMPION|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "film_inventory_df = inventory_df.select(\"film_id\").distinct()\n",
    "films_not_in_inventory = film_df.join(film_inventory_df, \"film_id\", \"left_anti\")\n",
    "films_not_in_inventory.select('title').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b0c9d",
   "metadata": {},
   "source": [
    "(e) Top 3 actors in “Children” category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "062fce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-----+\n",
      "|first_name|last_name|count|\n",
      "+----------+---------+-----+\n",
      "|    SIDNEY|    CROWE|    9|\n",
      "|   RICHARD|     PENN|    9|\n",
      "|      EWAN|  GOODING|    9|\n",
      "+----------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "children_category_id = category_df.filter(col('name') == 'Children').select('category_id').collect()[0][0]\n",
    "top_actors_children = film_actor_df \\\n",
    "    .join(film_category_df.filter(col(\"category_id\") == children_category_id), \"film_id\") \\\n",
    "    .join(actor_df, \"actor_id\") \\\n",
    "    .groupBy(\"first_name\", \"last_name\") \\\n",
    "    .count() \\\n",
    "    .orderBy(desc(\"count\")) \\\n",
    "    .limit(3)\n",
    "\n",
    "top_actors_children.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8365fb2",
   "metadata": {},
   "source": [
    "(f) Cities with active/inactive customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558a2e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------+------------------+\n",
      "|              city|active_customers|inactive_customers|\n",
      "+------------------+----------------+------------------+\n",
      "|          Uluberia|               0|                 1|\n",
      "|         Najafabad|               0|                 1|\n",
      "|         Pingxiang|               0|                 1|\n",
      "|          Xiangfan|               0|                 1|\n",
      "|        Kumbakonam|               0|                 1|\n",
      "|       Szkesfehrvr|               0|                 1|\n",
      "|  Charlotte Amalie|               0|                 1|\n",
      "|            Kamyin|               0|                 1|\n",
      "|            Daxian|               0|                 1|\n",
      "|     Coatzacoalcos|               0|                 1|\n",
      "|           Wroclaw|               0|                 1|\n",
      "|            Ktahya|               0|                 1|\n",
      "|           Bat Yam|               0|                 1|\n",
      "|   Southend-on-Sea|               0|                 1|\n",
      "|            Amroha|               0|                 1|\n",
      "|A Corua (La Corua)|               1|                 0|\n",
      "|          Fengshan|               1|                 0|\n",
      "|          Chisinau|               1|                 0|\n",
      "|              Linz|               1|                 0|\n",
      "|           Udaipur|               1|                 0|\n",
      "+------------------+----------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum as spark_sum, desc\n",
    "\n",
    "customer_df = read_table('customer')\n",
    "address_df = read_table('address')\n",
    "city_df = read_table('city')\n",
    "customer_with_address = customer_df.join(address_df, 'address_id').join(city_df, 'city_id')\n",
    "\n",
    "cities_activity = customer_with_address.groupBy(\"city\") \\\n",
    "    .agg(\n",
    "        spark_sum(col(\"active\")).alias(\"active_customers\"),\n",
    "        spark_sum(1 - col(\"active\")).alias(\"inactive_customers\")\n",
    "    ).orderBy(desc(\"inactive_customers\"))\n",
    "\n",
    "cities_activity.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc86505",
   "metadata": {},
   "source": [
    "(g) Category with highest rental hours in cities (names start with “a” or contain “-”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d0db17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+-----------+\n",
      "|              city|       name|total_hours|\n",
      "+------------------+-----------+-----------+\n",
      "|A Corua (La Corua)|     Sci-Fi|    3354900|\n",
      "|A Corua (La Corua)|     Family|    2914620|\n",
      "|A Corua (La Corua)|   Children|    2829000|\n",
      "|A Corua (La Corua)|      Drama|    2543520|\n",
      "|A Corua (La Corua)|    Foreign|    2330520|\n",
      "|A Corua (La Corua)|      Music|    2326800|\n",
      "|A Corua (La Corua)|Documentary|    2166480|\n",
      "|A Corua (La Corua)|      Games|    2072700|\n",
      "|A Corua (La Corua)|  Animation|    1813980|\n",
      "|A Corua (La Corua)|     Sports|    1638120|\n",
      "|A Corua (La Corua)|        New|    1632720|\n",
      "|A Corua (La Corua)|     Travel|    1544340|\n",
      "|A Corua (La Corua)|   Classics|    1482120|\n",
      "|A Corua (La Corua)|     Comedy|    1394880|\n",
      "|A Corua (La Corua)|     Horror|    1279740|\n",
      "|A Corua (La Corua)|     Action|     389220|\n",
      "|              Abha|     Action|    4265700|\n",
      "|              Abha|    Foreign|    3119040|\n",
      "|              Abha|   Children|    2407020|\n",
      "|              Abha|   Classics|    1985760|\n",
      "+------------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----------+-----------+\n",
      "|                city|       name|total_hours|\n",
      "+--------------------+-----------+-----------+\n",
      "|Augusta-Richmond ...|      Games|    4902240|\n",
      "|Augusta-Richmond ...|     Sports|    2976780|\n",
      "|Augusta-Richmond ...|      Drama|    2133000|\n",
      "|Augusta-Richmond ...|      Music|    1972080|\n",
      "|Augusta-Richmond ...|     Horror|    1938600|\n",
      "|Augusta-Richmond ...|     Travel|    1860780|\n",
      "|Augusta-Richmond ...|   Classics|    1618500|\n",
      "|Augusta-Richmond ...|     Sci-Fi|    1564740|\n",
      "|Augusta-Richmond ...|   Children|    1464120|\n",
      "|Augusta-Richmond ...|  Animation|    1104900|\n",
      "|Augusta-Richmond ...|    Foreign|     922560|\n",
      "|Augusta-Richmond ...|     Comedy|     694440|\n",
      "|Augusta-Richmond ...|Documentary|     660120|\n",
      "|Augusta-Richmond ...|        New|     617400|\n",
      "|Augusta-Richmond ...|     Family|     515460|\n",
      "|Augusta-Richmond ...|     Action|     186840|\n",
      "|         Beni-Mellal|      Drama|    3536040|\n",
      "|         Beni-Mellal|   Children|    2245440|\n",
      "|         Beni-Mellal|     Comedy|    2139960|\n",
      "|         Beni-Mellal|Documentary|    2066820|\n",
      "+--------------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rental_info = rental_df \\\n",
    "    .join(inventory_df, \"inventory_id\") \\\n",
    "    .join(film_category_df, \"film_id\") \\\n",
    "    .join(category_df, \"category_id\") \\\n",
    "    .join(customer_with_address, \"customer_id\") \\\n",
    "    .withColumn(\"rental_hours\", col(\"return_date\").cast(\"long\") - col(\"rental_date\").cast(\"long\"))\n",
    "\n",
    "\n",
    "rental_info.filter(col(\"city\").startswith(\"A\")) \\\n",
    "    .groupBy(\"city\", \"name\") \\\n",
    "    .agg(spark_sum(\"rental_hours\").alias(\"total_hours\")) \\\n",
    "    .orderBy(\"city\", desc(\"total_hours\")) \\\n",
    "    .show()\n",
    "\n",
    "\n",
    "rental_info.filter(col(\"city\").contains(\"-\")) \\\n",
    "    .groupBy(\"city\", \"name\") \\\n",
    "    .agg(spark_sum(\"rental_hours\").alias(\"total_hours\")) \\\n",
    "    .orderBy(\"city\", desc(\"total_hours\")) \\\n",
    "    .show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
